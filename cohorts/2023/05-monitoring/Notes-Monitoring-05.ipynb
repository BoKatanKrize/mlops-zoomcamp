{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e533455",
   "metadata": {},
   "source": [
    "## 5.1 - Intro to ML monitoring\n",
    "\n",
    "Monitoring is a crucial part of MLOps. It involves tracking the performance of machine learning models in production, system metrics, data quality, and more. Over time, the quality of models can degrade, and monitoring can help detect this.\n",
    "\n",
    "\n",
    "### 5.1.1. Metrics to monitor (compulsory)\n",
    "What metrics should we add to our monitoring to fully capture the ML service we are focusing on?\n",
    "\n",
    "1. **Service health** -> answers the question *does it work?*\n",
    "2. **Model performance** -> *how good the models are?* E.g.:\n",
    "    - Regression problems: rmse, ...\n",
    "    - Classification problems: precision, recall, ...\n",
    "    \n",
    "3. **Data quality and integrity** -> *how good is the input data?* *where and how can be improved?* E.g. \n",
    "    - Amount of missing values, calculate value ranges, ...\n",
    "4. **Data and concept drift** -> The service works in a constantly changing environment, thus *is the model still relevant?* \n",
    "    - Compares the distribution of input data to model's output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3632041",
   "metadata": {},
   "source": [
    "### 5.1.2. Metrics to monitor (additional/optional)\n",
    "There are also other metrics we can pay attention to, depending on the sensitivity, risk and resources involved:\n",
    "- Performance by segment: if you have a large diversity in your dataset\n",
    "- Model bias / fairness: in case of sensitive domain area (e.g., human studies in medicine)\n",
    "- Monitor for outliers: in case case each individual error is very high\n",
    "- Explainability: e.g., in recommender systems, how this recommendation is generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce592e",
   "metadata": {},
   "source": [
    "### 5.1.3. Monitoring depending on deployment type\n",
    "\n",
    "*Note:* You can reuse existing monitoring architecture for ML models (monitoring traditional software applications). This can save time and resources as you don't need to build a new monitoring system from scratch.\n",
    "\n",
    "The approach we use to deploy the model will influence how monitoring is done.\n",
    "\n",
    "1. **Batch deployment**: most of the metrics previously described can be analyzed in batch mode. \n",
    "    - E.g., you can take the data from most recent batch as current data and compare with reference\n",
    "\n",
    "2. **Non-batch deployment**: e.g., web-services. It becomes more complicated. Not every metric can be calculated in real time. \n",
    "    - Instead, it's more effective to analyze it as a collection (i.e., batch-like).  \n",
    "    - We can use window functions, wait until you collect a small batch unit, then calculate all these metrics and store it somewhere.\n",
    "    - This means that even if your service is purely online, you can still do monitoring in batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc72fb2",
   "metadata": {},
   "source": [
    "### 5.1.4. Monitoring architecture\n",
    "\n",
    "The monitoring scheme we are going to use for this week can be used for both batch and non-batch deployment:\n",
    "\n",
    "![title](images/monitoring-scheme.png)\n",
    "\n",
    "- Taxi ride predicition service (either web or batch)\n",
    "- Productionize the service  and outputting some logs\n",
    "- We are building the monitoring on top of these logs (as local files):\n",
    "    1. Implement monitoring jobs with **Prefect**\n",
    "    2. We use **Evidently AI** as the evaluation layer: read prediction logs by batch, analyze, calculate metrics and store in postgresql\n",
    "       - *Evidently* is an open-source Python library to evaluate, test, and monitor the performance of machine learning models from the validation phase to production. It allows you to detect potential issues early.\n",
    "    3. Later, we use this database as source for Dashboard (**Grafana**) containing evolution of different metrics\n",
    "       - *Grafana* is an open-source platform for monitoring and observability. It allows you to query, visualize, alert on, and understand your metrics no matter where they are stored. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4084302",
   "metadata": {},
   "source": [
    "## 5.2 - Environment setup\n",
    "\n",
    "### 5.2.1 Python packages\n",
    "\n",
    "First, we need to create a working directory for our project in ```/05-monitoring``` directory\n",
    "\n",
    "```\n",
    "$ mkdir taxi_monitoring\n",
    "```\n",
    "\n",
    "Next, we'll work in ```mlops-zoomcamp``` conda virtual environment. Thus:\n",
    "\n",
    "```\n",
    "$ conda activate mlops-zoomcamp\n",
    "```\n",
    "\n",
    "We'll create a ```requirements.txt``` file in ```taxi_monitoring/``` to list all the necessary Python libraries for our project.\n",
    "\n",
    "```\n",
    "prefect\n",
    "tqdm\n",
    "requests\n",
    "joblib\n",
    "pyarrow\n",
    "psycopg\n",
    "psycopg_binary\n",
    "evidently \n",
    "pandas\n",
    "numpy\n",
    "scikit-learn\n",
    "jupyter\n",
    "matplotlib\n",
    "```\n",
    "\n",
    "Now, we'll install all the Python packages listed in the ```requirements.txt``` file.\n",
    "\n",
    "```\n",
    "$ pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b09e6c",
   "metadata": {},
   "source": [
    "### 5.2.2 Docker Compose\n",
    "\n",
    "#### Definition of ```compose.yaml```\n",
    "\n",
    "A Docker Compose file is used to define and manage a multi-container Docker application. It's a YAML file that contains all the necessary configurations to run the application. The services defined in this file are typically used in a development environment for testing or in a production environment for deployment.\n",
    "\n",
    "We create the YAML file in ```taxi_monitoring/```:\n",
    "\n",
    "```\n",
    "(mlops-zoomcamp) $ touch compose.yaml\n",
    "```\n",
    "\n",
    "We'll configure the ```compose.yaml``` so that can be typically used in a scenario where you want to set up a monitoring system for your application. It uses these 3 services:\n",
    "\n",
    "- **Postgres database**: stores application data\n",
    "- **Adminer**: provides a web interface for managing the Postgres database\n",
    "- **Grafana**: creates visualizations and dashboards based on the data in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d4a20",
   "metadata": {},
   "source": [
    "Here is how the ```compose.yaml``` would look like:\n",
    "\n",
    "```dockerfile\n",
    "\n",
    "version: '3.7'\n",
    "\n",
    "# Declares volumes that can be used by the services (in this specific file, the volumes declared are not used). Volumes are used to store your artifacts independently of the status of your containers (up or down). It's especially relevant for Grafana\n",
    "volumes:\n",
    "  grafana_data: {}\n",
    "\n",
    "# Defines networks that can be used by the services\n",
    "networks:\n",
    "  front-tier:\n",
    "  back-tier:\n",
    "\n",
    "# Defines the services that make up your app\n",
    "services:\n",
    "  db:\n",
    "    # Specifies the Docker image to use for this service\n",
    "    image: postgres\n",
    "    # Ensures that the service is always restarted if it stops\n",
    "    restart: always\n",
    "    # Sets environment variables for the service\n",
    "    environment:\n",
    "      # Sets the password for the Postgres database\n",
    "      POSTGRES_PASSWORD: example\n",
    "    # Maps ports between the host and the container\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    # Specifies the networks that this service is part of\n",
    "    networks:\n",
    "      - back-tier\n",
    "\n",
    "  adminer:\n",
    "    image: adminer\n",
    "    restart: always\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "    networks:\n",
    "      # Communicate with postgres\n",
    "      - back-tier\n",
    "      # We need access (browser)\n",
    "      - front-tier  \n",
    "\n",
    "  grafana:\n",
    "    image: grafana/grafana\n",
    "    # Sets the user ID under which the service will run. The service uses a specific user ID to run and mounts several volumes for configuration and dashboards.\n",
    "    user: \"472\"\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    # Maps local directories to directories inside the container\n",
    "    volumes:\n",
    "      # :ro -> read-only\n",
    "      - ./config/grafana_datasources.yaml:/etc/grafana/provisioning/datasources/datasource.yaml:ro\n",
    "      - ./config/grafana_dashboards.yaml:/etc/grafana/provisioning/dashboards/dashboards.yaml:ro\n",
    "      - ./dashboards:/opt/grafana/dashboards\n",
    "    networks:\n",
    "      # Communicate with postgres\n",
    "      - back-tier\n",
    "      # Access our dashboard from browser\n",
    "      - front-tier\n",
    "    restart: always\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7f069",
   "metadata": {},
   "source": [
    "#### Grafana data source configuration\n",
    "\n",
    "We'll create a Grafana data source configuration file. It's used to define the data sources that Grafana should connect to. A data source in Grafana represents a back-end database, such as PostgreSQL. \n",
    "\n",
    "In your project directory, create a new directory named ```config``` and a file within it named ```grafana_datasources.yaml```:\n",
    "\n",
    "```\n",
    "$ mkdir config\n",
    "$ touch config/grafana_datasources.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a129c",
   "metadata": {},
   "source": [
    "The content of ```grafana_datasources.yaml``` is as follows:\n",
    "\n",
    "```dockerfile\n",
    "# Specifies the version of the configuration file format being used\n",
    "apiVersion: 1\n",
    "\n",
    "# Defines the data sources that Grafana should connect to\n",
    "datasources:\n",
    "    # name of the data source\n",
    "  - name: PostgreSQL\n",
    "    # type of the data source as PostgreSQL\n",
    "    type: postgres\n",
    "    # Grafana will act as a proxy between the data source and the clients\n",
    "    access: proxy\n",
    "    # PostgreSQL service defined in the Docker Compose file (including port)\n",
    "    url: db.:5432\n",
    "    # Name of the database within the PostgreSQL server that Grafana should connect to.\n",
    "    database: test\n",
    "    # Sets the username to be used for authentication when connecting to the PostgreSQL server.\n",
    "    user: postgres\n",
    "    # Contains sensitive data (in this case, the password) that is securely stored. Here, the password is set to \"example\".\n",
    "    secureJsonData:\n",
    "      password: 'example'\n",
    "    # Contains additional JSON data. Here, SSL/TLS encryption for the connection is disabled.\n",
    "    jsonData:\n",
    "      sslmode: 'disable'\n",
    "```\n",
    "\n",
    "This configuration file is used in the context of the ```compose.yaml``` setup we provided earlier. The Grafana service in the Docker Compose file uses this configuration file to set up its connection to the PostgreSQL database.\n",
    "\n",
    "This setup allows Grafana to pull data from the PostgreSQL database, which it can then use to create visualizations and dashboards. This is particularly useful in a monitoring setup, where you might want to visualize metrics from your application that are stored in the PostgreSQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c926e1b",
   "metadata": {},
   "source": [
    "### 5.2.3 Build and Run Docker Compose\n",
    "\n",
    "Finally, we'll build and run our Docker Compose configuration. There are different options:\n",
    "\n",
    "```$ docker compose build``` : only builds the images, does not start the containers\n",
    "\n",
    "```$ docker compose up``` : builds the images if the images do not exist and starts the containers\n",
    "\n",
    "```$ docker compose up --build``` : forced to build the images even when not needed\n",
    "\n",
    "In our case we use the 3rd option. You should see that all your containers are successfully created. You can verify this by accessing \n",
    "\n",
    "- Grafana : ```localhost:3000```. When accessing for the 1st time, ```user:admin``` and ```password:admin```\n",
    "- Adminer : ```localhost:8080```\n",
    "\n",
    "and use \n",
    "\n",
    "``` $ docker compose down```\n",
    "\n",
    "to stop the containers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d792d",
   "metadata": {},
   "source": [
    "## 5.3 Prepare reference and model\n",
    "\n",
    "Before we can start monitoring our machine learning model, we need to establish a baseline. This involves gathering initial data and training a model that we can use as a reference point for future comparisons.\n",
    "\n",
    "Within the directory ```taxi_monitoring/```, we create two extra folders: ```models``` and ```data```. From now on, the following content will refer to the functions implemented in the notebook ```baseline_model_nyc_taxi_data.ipynb```.\n",
    "\n",
    "1. First, we need to import all the necessary libraries for our project. This includes libraries for handling requests, datetime operations, data manipulation (Pandas), machine learning (Scikit-learn), model persistence (Joblib), progress bars (tqdm), and data drift and model performance monitoring (Evidently).\n",
    "\n",
    "2. \n",
    "```python \n",
    "def download_files()\n",
    "```\n",
    "This function downloads files from a specified URL and saves them to a local directory. It uses the ```requests``` library to send a GET request to the URL and download the file, and the ```tqdm``` library to display a progress bar.\n",
    "\n",
    "3. \n",
    "```python\n",
    "def preprocess_data()\n",
    "```\n",
    "This function preprocesses the data by calculating the duration of each trip in minutes and filtering out trips with unrealistic durations and passenger counts.\n",
    "\n",
    "4. ```python\n",
    "def train_and_evaluate()\n",
    "``` \n",
    "This function trains a Linear Regression model on the training data and evaluates it on the validation data. The script calculates the Mean Absolute Error (MAE) of the predictions on both the training and validation data.\n",
    "\n",
    "5. ```python\n",
    "def save_model_and_data()\n",
    "``` \n",
    "This function saves the trained model and the validation data for future use. It uses the ```joblib.dump``` function to save the model and the ```polars.DataFrame.write_parquet``` method to save the validation data. This step is important for model deployment and monitoring, as we'll need to load the model and reference data in the future to calculate dataset drift when compared with production behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f47f34",
   "metadata": {},
   "source": [
    "## 5.4 Generate Evidently Report\n",
    "\n",
    "```python\n",
    "def generate_report()\n",
    "```\n",
    "This function generates an Evidently report that provides insights into the performance of the model. It specifies the target variable, prediction variable, and the numerical and categorical features. The report checks for column drift, dataset drift, and missing values in the dataset.\n",
    "\n",
    "In the context of the report generated by the evidently library, **data drift** refers to a concept that measures the changes in data distribution over time. It helps in identifying situations where the model might be operating on data that is significantly different from the data it was trained on, which can indicate the need for model retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e08d58",
   "metadata": {},
   "source": [
    "## 5.5  Dummy monitoring\n",
    "\n",
    "Now we will put everything together with an example using dummy data. The implementation can be found in ```taxi_monitoring/dummy_metrics_calculation.py```\n",
    "\n",
    "### 5.5.1  Set up dummy data\n",
    "\n",
    "- We will start by preparing the database and creating tables with dummy data \n",
    "- Next, we will insert timestamp values into the database table. \n",
    "- Finally, we will set up and access a PostgreSQL database for Grafana dashboard.\n",
    "\n",
    "In the following, we will describe the content of ```dummy_metrics_calculation.py```\n",
    "\n",
    "1. ```python \n",
    "def prep_db()\n",
    "```\n",
    "This function ensures that s PostgreSQL database exists and creates it if necessary. It then establishes a connection to the database and creates a table with the specified columns. \n",
    "\n",
    "2. ```python \n",
    "def calculate_dummy_metrics_postgresql()\n",
    "``` \n",
    "This function calculates dummy metrics and loads them into the table. It generates random values for three variables and inserts them into the table along with the current timestamp.\n",
    "\n",
    "3. ```python\n",
    "def main()\n",
    "```\n",
    "In the main function, we prepare the database and then run a loop to calculate and insert dummy metrics into the table. We also calculate the time delay to simulate real production usage (also, it will be easier to visualize and see how data changes in Grafana).\n",
    "\n",
    "### 5.5.2  Launch containers & dummy script\n",
    "\n",
    "We can now run the script. But first we need to activate the containers:\n",
    "\n",
    "```\n",
    "$ docker compose up\n",
    "```\n",
    "and then run the script:\n",
    "\n",
    "```\n",
    "$ python dummy_metrics_calculation.py\n",
    "```\n",
    "After waiting for a couple of data sent, we can now go to our browser and open Adminer at ```localhost:8080```. We use the following parameters:\n",
    "- System: PostgreSQL\n",
    "- Server: db\n",
    "- Username: postgres\n",
    "- Password: example\n",
    "- Database: test\n",
    "\n",
    "The dummy_table looks like this:\n",
    "\n",
    "![title](images/dummy.png)\n",
    "\n",
    "and we can see how quite a bit of data has been written already:\n",
    "\n",
    "![title](images/dummy_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa7f17",
   "metadata": {},
   "source": [
    "### 5.5.3  Access dummy data from Grafana\n",
    "\n",
    "Now, let's go to Grafana and see whether we are able to access those data from Grafana. If we configured our Grafana and PostgreSQL correctly, we should be able to create a new dashboard. \n",
    "\n",
    "To access Grafana through the browser (containers are running) -> ```localhost:3000```. \n",
    "\n",
    "- We need to create a new dashboard associated with PostgreSQL. \n",
    "- By default a visualization will be autogenerated (not related with our data)\n",
    "- To visualize our data, we need to select our table name and columns we are interested. For example, for value1:\n",
    "\n",
    "![title](images/grafana1.png)\n",
    "\n",
    "We can create several visualizations as well (e.g., value1 and value3):\n",
    "\n",
    "![title](images/grafana2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e300a",
   "metadata": {},
   "source": [
    "## 5.6  Data Quality Monitoring - NYC taxi trip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c9915",
   "metadata": {},
   "source": [
    "### 5.6.1 Prepare script\n",
    "\n",
    "Now we delve into a crucial aspect of MLOps: monitoring the performance of deployed machine learning models over time. The primary objective is to identify and log any changes in the model's performance, a process known as **drift detection**. Drift can occur when the statistical properties of the target variable, which the model aims to predict, alter unexpectedly over time, potentially leading to a decline in the model's performance.\n",
    "\n",
    "To orchestrate the tasks involved in calculating and storing drift metrics, we employ the **Prefect** library. The **Evidently** library is utilized to compute three types of metrics:\n",
    "\n",
    "- Column Drift\n",
    "- Dataset Drift\n",
    "- Missing Values\n",
    "\n",
    "These metrics, computed for each day's data, are stored in a PostgreSQL database for subsequent analysis. Designed to operate as a batch job, the script processes a large volume of data at once, instead of handling each data point individually in real-time.\n",
    "\n",
    "Included in the script ```taxi_monitoring/evidently_metrics_calculation.py``` we define several tasks that will be used in our Prefect pipeline:\n",
    "\n",
    "1. ```python\n",
    "@task\n",
    "def prep_db():\n",
    "```\n",
    "which prepares the database, creating the necessary table if it doesn't already exist.\n",
    "\n",
    "2. ```python\n",
    "@task\n",
    "def calculate_metrics_postgresql(curr, i):\n",
    "```\n",
    "calculates the metrics for each day ```i``` and inserts them into the database. \n",
    "\n",
    "3. ```python\n",
    "@flow\n",
    "def batch_monitoring_backfill():\n",
    "```\n",
    "Finally, this flow orchestrates the entire process. It calls the ```prep_db()``` task to prepare the database, then loops over each day in the time period, calls the ```calculate_metrics_postgresql()``` task to calculate the metrics for that day, and inserts them into the database. It also ensures that the metrics are sent to the database at a rate that does not exceed the ```SEND_TIMEOUT```.\n",
    "\n",
    "In summary, with periodic execution (e.g., daily), the script enables continuous monitoring of the model's performance, providing early warning signs if performance is deteriorating due to drift. This information can trigger model retraining or other interventions to maintain performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fffd901",
   "metadata": {},
   "source": [
    "### 5.6.2 Run containers, Prefect and script\n",
    "\n",
    "We can now \n",
    "\n",
    "1. run the containers:\n",
    "\n",
    "```\n",
    "$ docker compose up\n",
    "```\n",
    "\n",
    "2. start Prefect locally/cloud:\n",
    "```\n",
    "$ prefect server start\n",
    "```\n",
    "Once the Prefect server is up and running, we make sure that we apply the API URL to our Prefect configuration so that we're pointing to the correct API URL and the workflow metadata is correctly sent to the server UI. Therefore, in a new CLI window, we run the following command:\n",
    "```\n",
    "$ prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api\n",
    "```\n",
    "\n",
    "3. and run the script:\n",
    "\n",
    "```\n",
    "$ python evidently_metrics_calculation.py\n",
    "```\n",
    "\n",
    "Then we can access Prefect UI at ```localhost:4200```. In the figure below, we can observe the iteration has reached 10 days:\n",
    "\n",
    "![title](images/monitoring-prefect.png)\n",
    "\n",
    "and navigate to Adminer at ```localhost:8080``` to observe that the metrics table has been created:\n",
    "\n",
    "![title](images/monitoring-adminer.png)\n",
    "\n",
    "Finally, we demonstrate how to construct a dashboard with panels and metrics in Grafana, offering a visual representation of the model's performance and any detected drift.\n",
    "\n",
    "To access Grafana through the browser (containers are running) -> ```localhost:3000```. In this case we want to monitor *prediction_drift*. We need to make sure that we zoom the data to the historical timestamps, as we are not recording the present time but February 2022:\n",
    "\n",
    "![title](images/grafana-monitoring.png)\n",
    "\n",
    "We can also add the other two metrics:\n",
    "\n",
    "![title](images/grafana-monitoring2.png)\n",
    "\n",
    "Next, we will discuss how to save the dashboard and ensure it can be loaded every time the Docker container is rerun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f2ccde",
   "metadata": {},
   "source": [
    "## 5.7 Save Grafana Dashboard\n",
    "\n",
    "\n",
    "### 5.7.1 Saving Grafana dashboard configurations\n",
    "With Grafana, we don't need to recreate all the panels again, but we can just access them from the dashboards. Remember on ```compose.yaml``` we used\n",
    "\n",
    "```dockerfile\n",
    "grafana:\n",
    "    image: grafana/grafana\n",
    "    user: \"472\"\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    volumes:\n",
    "      - ./config/grafana_datasources.yaml:/etc/grafana/provisioning/datasources/datasource.yaml:ro\n",
    "      #- ./config/grafana_dashboards.yaml:/etc/grafana/provisioning/dashboards/dashboards.yaml:ro\n",
    "      #- ./dashboards:/opt/grafana/dashboards\n",
    "    networks:\n",
    "      - back-tier\n",
    "      - front-tier\n",
    "    restart: always\n",
    "```\n",
    "where ```config/grafana_dashboards.yaml``` is a configuration file used to set up Grafana dashboards for monitoring machine learning models. The dashboards are stored ```dashboards/``` and Grafana scans for changes at the specified interval. We can uncomment these two volumes so that the dashboard can be saved.\n",
    "\n",
    "```yaml\n",
    "\n",
    "apiVersion: 1\n",
    "\n",
    "providers:\n",
    "  # <string> an unique provider name. Required\n",
    "  - name: 'Evidently Dashboards'\n",
    "    # <int> Org id. Default to 1\n",
    "    orgId: 1\n",
    "    # <string> name of the dashboard folder.\n",
    "    folder: ''\n",
    "    # <string> folder UID. will be automatically generated if not specified\n",
    "    folderUid: ''\n",
    "    # <string> provider type. Default to 'file'\n",
    "    type: file\n",
    "    # <bool> disable dashboard deletion\n",
    "    disableDeletion: false\n",
    "    # <int> how often Grafana will scan for changed dashboards\n",
    "    updateIntervalSeconds: 10\n",
    "    # <bool> allow updating provisioned dashboards from the UI\n",
    "    allowUiUpdates: false\n",
    "    options:\n",
    "      # <string, required> path to dashboard files on disk. Required when using the 'file' type\n",
    "      path: /opt/grafana/dashboards\n",
    "      # <bool> use folder names from filesystem to create folders in Grafana\n",
    "      foldersFromFilesStructure: true\n",
    "\n",
    "```\n",
    "Make sure you have the Grafana dashboard configuration file ```dashboards/data_drift.json```. The content of this JSON file can be obtained from Grafana as follows:\n",
    "\n",
    "![title](images/grafana-json.png)\n",
    "\n",
    "### 5.7.2 Reloading Docker and accessing saved dashboard in Grafana.\n",
    "\n",
    "We stop docker:\n",
    "\n",
    "```\n",
    "$ docker compose down\n",
    "```\n",
    "\n",
    "and then rerun the containers:\n",
    "\n",
    "```\n",
    "$ docker compose up\n",
    "```\n",
    "\n",
    "and the script:\n",
    "\n",
    "```\n",
    "$ python evidently_metrics_calculation.py\n",
    "```\n",
    "\n",
    "By accessing Grafana through the browser (containers are running) -> ```localhost:3000```, the visualizations are already loaded. If you access Grafana before the script is completed, the visualizations will show only the days calculated so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17530891",
   "metadata": {},
   "source": [
    "## 5.8 Debugging with test suites and reports\n",
    "\n",
    "Now we will explore how to debug and monitor machine learning models using the Evidently library. \n",
    "\n",
    "- Debugging involves identifying, isolating, and fixing issues that may affect the performance of a machine learning model. \n",
    "\n",
    "- Monitoring, on the other hand, is the continuous observation of the model's performance over time to detect any significant changes or anomalies.\n",
    "\n",
    "Evidently provides powerful tools for both debugging and monitoring. It offers Test Suites and Reports that help in understanding the model's behavior and performance.\n",
    "\n",
    "**Test Suites** in Evidently allow us to run a series of tests on the data to check for various conditions, such as data drift. If any of the tests fail, it indicates a potential issue that needs to be debugged.\n",
    "\n",
    "**Reports** in Evidently provide a comprehensive analysis of the data and the model. They calculate various metrics and provide visualizations that help in understanding the state of the data and the model. For instance, a Data Drift report can show how the features' distributions have changed over time, indicating drift.\n",
    "\n",
    "By leveraging these tools, we can effectively debug and monitor our machine learning models, ensuring their robustness and reliability in production environments.\n",
    "\n",
    "The code is provided at ```taxi_monitoring/debugging_nyc_taxi_data.ipynb```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlops-zoomcamp]",
   "language": "python",
   "name": "conda-env-mlops-zoomcamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
