{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b9acea",
   "metadata": {},
   "source": [
    "# CI/CD with GitHub Actions\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Overview\n",
    "- Automate the IaC presented so far with Terraform \n",
    "- by building a complete CI/CD pipeline using GitHub Actions \n",
    "- The goal of our CI/CD pipeline is, for every new commit to the GitHub repository: \n",
    "    - automatically test a pull request (CI)\n",
    "    - build and push container image to a registry (CD)\n",
    "    - deploy the updated lambda service to production (CD)\n",
    "    \n",
    "![title](images/ci_cd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c5ec12",
   "metadata": {},
   "source": [
    "### 1.2 About workflows\n",
    "\n",
    "A workflow is a configurable automated process that will run one or more jobs. Workflows are defined by a YAML file checked in to your repository and will run when triggered by an event in your repository, or they can be triggered manually, or at a defined schedule.\n",
    "\n",
    "Workflows are defined in the ```.github/workflows``` directory in a repository, and a repository can have multiple workflows, each of which can perform a different set of tasks. For example, you can have one workflow to build and test pull requests and another workflow to deploy your application every time a release is created.\n",
    "\n",
    "GitHub Actions provides us with standard virtual machines to execute our jobs (such as tests) without setting up any extra infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46502a9",
   "metadata": {},
   "source": [
    "### 1.3 Summary CI/CD workflows\n",
    "\n",
    "The **CI** workflow consists of two jobs and will be triggered when we create a pull request from a feature branch for a new commit to the repo. For example, given the image below, we can do a pull request from the branch ```feature/week6b-iac``` to the branch ```develop```:\n",
    "\n",
    "![title](images/github-branches.png)\n",
    "\n",
    "The two jobs are as follows:\n",
    "\n",
    "1. Responsible to auto-test our inference service locally and on cloud\n",
    "    - Unit tests\n",
    "    - Integration tests\n",
    "2. It will also run the Terraform plan on our specified Terraform state file to compile and validate any infrastructure changes\n",
    "    - ```$ terraform init```\n",
    "    - ```$ terraform plan```\n",
    "\n",
    "The **CD** workflow consists of one job with a series of steps. It will be triggered only when your pull request is approved and merged to the main branch.\n",
    "- Step 1: define infra using Terraform. This will be done automatically if ```$ terraform plan``` from CI detects any changes\n",
    "    - ```$ terraform init```\n",
    "    - ```$ terraform apply```\n",
    "- Step 2: Build docker image and push it to ECR repo\n",
    "- Step 3: once a new version of Lambda function is published, the Lambda config will be updated (infra is kept intact, just the Lambda application logic is updated). That's why Step 2 and 3 are kept separate. If Step 2 were integrated, it would change the infra every time the docker image is built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c890faf",
   "metadata": {},
   "source": [
    "## 2. CI workflow\n",
    "\n",
    "*Note:*\n",
    "\n",
    "- The stage environment is a pre-production environment that acts as an intermediary step between development and production.\n",
    "\n",
    "- The production environment is the live and operational environment where the machine learning system serves real users or applications.\n",
    "\n",
    "Let's create the folder ```.github/workflows``` in the project repo. Which this folder we will define two files:\n",
    "- For CI: ```ci-tests.yaml```\n",
    "- For CD: ```cd-deploy.yaml```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f612d",
   "metadata": {},
   "source": [
    "### 2.1 ```ci-tests.yaml```\n",
    "\n",
    "Let's go through the CI workflow defined in ```ci-tests.yaml``` step by step:\n",
    "\n",
    "1. The workflow is named \"CI-Tests\" and will be triggered on pull requests targeting the 'develop' branch and when changes are made to files under the ```06-best-practices/code/``` directory\n",
    "    ```yaml\n",
    "    name: CI-Tests\n",
    "    on:\n",
    "      pull_request:\n",
    "        branches:\n",
    "          - 'develop'\n",
    "        paths:\n",
    "          - '06-best-practices/code/**'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695377a1",
   "metadata": {},
   "source": [
    "2. The workflow defines three environment variables: ```AWS_DEFAULT_REGION```, ```AWS_ACCESS_KEY_ID```, and ```AWS_SECRET_ACCESS_KEY```. These variables will be used to configure AWS credentials for later steps.\n",
    "```yaml\n",
    "    env:\n",
    "      AWS_DEFAULT_REGION: 'eu-west-1'\n",
    "      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n",
    "      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b950f",
   "metadata": {},
   "source": [
    "3. The CI workflow defines two jobs: \"test\" and \"tf-plan\". Each job is an independent container and thus we will need to set up a new environment for each of them. Also, jobs run in parallel, so we need to make sure we don't have any interdependency. If we do, we need to explicitly define any interdependency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77d77a",
   "metadata": {},
   "source": [
    "4. Job \"test\":\n",
    "    - It runs on an 'ubuntu-latest' runner, which means it will execute on a virtual machine (VM) with the latest version of Ubuntu.\n",
    "    - The steps for this job include:\n",
    "        - Clone the code repository to the VM using ```actions/checkout@v2```. It will also install docker\n",
    "        - Setting up Python 3.9 in the VM using ```actions/setup-python@v2```.\n",
    "        - Installing dependencies in VM using pipenv in the ```06-best-practices/code``` directory.\n",
    "        - Running unit tests in VM with ```pipenv run pytest tests/``` in the ```06-best-practices/code``` directory.\n",
    "        - Running linting in VM using ```pipenv run pylint --recursive=y .``` in the ```06-best-practices/code``` directory.\n",
    "        - Configuring AWS credentials in VM using ```aws-actions/configure-aws-credentials@v1```.\n",
    "        - Running an integration test in VM by executing the ```run.sh``` script in the ```06-best-practices/code/integraton-test``` directory. We have modified the original script to include ```GITHUB_ACTIONS``` to detect if the environment from which the script is being run is a GitHub CI/CD environment or a local environment\n",
    "\n",
    "```yaml\n",
    "    jobs:\n",
    "      test:\n",
    "        runs-on: ubuntu-latest\n",
    "        steps:\n",
    "          - uses: actions/checkout@v2\n",
    "          - name: Set up Python 3.9\n",
    "            uses: actions/setup-python@v2\n",
    "            with:\n",
    "              python-version: 3.9\n",
    "\n",
    "          - name: Install dependencies\n",
    "            working-directory: \"06-best-practices/code\"\n",
    "            run: pip install pipenv && pipenv install --dev\n",
    "\n",
    "          - name: Run Unit tests\n",
    "            working-directory: \"06-best-practices/code\"\n",
    "            run: pipenv run pytest tests/\n",
    "\n",
    "          - name: Lint\n",
    "            working-directory: \"06-best-practices/code\"\n",
    "            run: pipenv run pylint --recursive=y .\n",
    "\n",
    "          - name: Configure AWS Credentials\n",
    "            uses: aws-actions/configure-aws-credentials@v1\n",
    "            with:\n",
    "              aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}\n",
    "              aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}\n",
    "              aws-region: ${{ env.AWS_DEFAULT_REGION }}\n",
    "\n",
    "          - name: Integration Test\n",
    "            working-directory: '06-best-practices/code/integraton-test'\n",
    "            run: |\n",
    "              . run.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c9031",
   "metadata": {},
   "source": [
    "5. Job \"tf-plan\":\n",
    "\n",
    "    - It runs on an 'ubuntu-latest' runner as well.\n",
    "    - The steps for this job include:\n",
    "        - Cloning the code repository using ```actions/checkout@v2```.\n",
    "        - Configuring AWS credentials using ```aws-actions/configure-aws-credentials@v1```.\n",
    "        - Setting up Terraform using ```hashicorp/setup-terraform@v2```.\n",
    "        - Running ```terraform init``` and ```terraform plan``` commands in the ```06-best-practices/code/infrastructure``` directory wrt the production environment (when running our Terraform plan in the earlier notebook we passed the variable file wrt the staging environment). Additionally, we are overriding the backend key in ```code/infrastructure/main.tf``` (originally it was defined for stage environment).\n",
    "      \n",
    "```yaml\n",
    "  tf-plan:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v2\n",
    "      - name: Configure AWS Credentials\n",
    "        uses: aws-actions/configure-aws-credentials@v1\n",
    "        with:\n",
    "          aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}\n",
    "          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}\n",
    "          aws-region: ${{ env.AWS_DEFAULT_REGION }}\n",
    "\n",
    "      - uses: hashicorp/setup-terraform@v2\n",
    "\n",
    "      - name: TF plan\n",
    "        id: plan\n",
    "        working-directory: '06-best-practices/code/infrastructure'\n",
    "        run: |\n",
    "          terraform init -backend-config=\"key=mlops-zoomcamp-prod.tfstate\" --reconfigure && terraform plan --var-file vars/prod.tfvars\n",
    "```\n",
    "\n",
    "Note: The steps involving AWS actions use the environment variables defined at the beginning of the workflow to configure AWS credentials. These environment variables are set using secrets in the GitHub repository (```Settings/Security/Secrets/Actions```), ensuring the credentials remain secure and not exposed in the workflow file.\n",
    "\n",
    "![title](images/github-secrets.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c7dbc",
   "metadata": {},
   "source": [
    "### 2.2 Execute CI workflow\n",
    "\n",
    "1. Go to the root of your repository\n",
    "2. Make sure you are in a feature branch (not the main branch). In our case, we call it ```feature/week6b-iac```\n",
    "    - Otherwise, you can ```$ git checkout -b feature/week6b-iac``` -> copy all of your commits to a new branch called ```feature/week6b-iac```\n",
    "    - Also, you must also have a branch called ```develop```\n",
    "3. Commit changes ```$ git commit -m \"ci-tests\"```\n",
    "4. Push to the feature branch, ```$ git push origin feature/week6b-iac```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397d15c",
   "metadata": {},
   "source": [
    "5. You can now do pull request ```feature/week6b-iac``` -> ```develop```\n",
    "\n",
    "![title](images/github-pull-request1.png)\n",
    "\n",
    "![title](images/github-pull-request2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58cc5ca",
   "metadata": {},
   "source": [
    "6. We can go to ```Actions``` and check the progress of the workflow (it will take a while to complete)\n",
    "\n",
    "![title](images/github-ci1.png)\n",
    "\n",
    "![title](images/github-ci2.png)\n",
    "\n",
    "And... it's successful!\n",
    "\n",
    "![title](images/github-ci3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc8c44",
   "metadata": {},
   "source": [
    "## 3. CD workflow\n",
    "\n",
    "Once we have created the CI workflow, we move to our CD pipeline.\n",
    "\n",
    "### 3.1 ```cd-deploy.yaml```\n",
    "\n",
    "Let's go through the CD workflow defined in ```cd-deploy.yaml``` step by step:\n",
    "\n",
    "1. The workflow is named \"CD-Deploy\" and is triggered when code changes are pushed to the 'develop' branch (we want this workflow to be triggered when the pull request from CI is merged to the 'develop' branch). Optionally you can add a path from where the commits are detected.\n",
    "    ```yaml\n",
    "    name: CD-Deploy\n",
    "    on:\n",
    "      push:\n",
    "        branches:\n",
    "          - 'develop'\n",
    "    #    paths:\n",
    "    #      - '06-best-practices/code/**'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07fd565",
   "metadata": {},
   "source": [
    "2. The workflow defines a **single job** named \"build-push-deploy\" that runs on an 'ubuntu-latest' VM. We use only one job as we want the steps of this workflow to run sequentially (not in parallel) and have them depend on the other ones.\n",
    "    ```yaml\n",
    "    jobs:\n",
    "      build-push-deploy:\n",
    "        runs-on: ubuntu-latest\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf6334",
   "metadata": {},
   "source": [
    "3. The steps for the \"build-push-deploy\" job are as follows:\n",
    "    - *Step 1:* Clone the repository to VM using ```actions/checkout@v3```.\n",
    "        ```yaml\n",
    "        steps:\n",
    "          - name: Check out repo\n",
    "            uses: actions/checkout@v3        \n",
    "        ```\n",
    "    - *Step 2:* Configure AWS credentials using ```aws-actions/configure-aws-credentials@v1``` to allow access to AWS services in the subsequent steps.\n",
    "```yaml\n",
    "          - name: Configure AWS Credentials\n",
    "            uses: aws-actions/configure-aws-credentials@v1\n",
    "            with:\n",
    "              aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n",
    "              aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n",
    "              aws-region: \"eu-west-1\"     \n",
    "        ```\n",
    "        \n",
    "    - *Step 3:* Set up Terraform in VM using ```hashicorp/setup-terraform@v2```. The ```terraform_wrapper: false``` option indicates that the workflow is responsible for running Terraform commands directly.\n",
    "```yaml\n",
    "          - uses: hashicorp/setup-terraform@v2\n",
    "            with:\n",
    "              terraform_wrapper: false       \n",
    "        ```\n",
    "    - *Step 4:* Perform ```terraform plan``` in the  ```06-best-practices/code/infrastructure``` directory of the VM to identify changes to be made to the infrastructure. The plan output will be saved to the variable ```tf-plan```\n",
    "```yaml\n",
    "           - name: TF plan\n",
    "             id: tf-plan\n",
    "             working-directory: '06-best-practices/code/infrastructure'\n",
    "             run: |\n",
    "               terraform init -backend-config=\"key=mlops-zoomcamp-prod.tfstate\" -reconfigure && terraform plan -var-file=vars/prod.tfvars\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e80e8",
   "metadata": {},
   "source": [
    "  \n",
    "   - *Step 5:* If the ```terraform plan``` is successful, perform ```terraform apply``` in the same directory of the VM to apply the changes and create/update the infrastructure. The apply is conditional on the success of the previous plan step. The flag ```-auto-approve``` allows to skip the approve step, as we can't pass manually a 'yes' in a CI/CD workflow. Additionally, we are printing some output values of the resources we are creating via Terraform. For Terraform to be able to do this, we are adding the output variables in ```infrastructure/main.tf```.\n",
    "```yaml\n",
    "          - name: TF Apply\n",
    "            id: tf-apply\n",
    "            working-directory: '06-best-practices/code/infrastructure'\n",
    "            if: ${{ steps.tf-plan.outcome }} == 'success'\n",
    "            run: |\n",
    "              terraform apply -auto-approve -var-file=vars/prod.tfvars\n",
    "              echo \"::set-output name=ecr_repo::$(terraform output ecr_repo | xargs)\"\n",
    "              echo \"::set-output name=predictions_stream_name::$(terraform output predictions_stream_name | xargs)\"\n",
    "              echo \"::set-output name=model_bucket::$(terraform output model_bucket | xargs)\"\n",
    "              echo \"::set-output name=lambda_function::$(terraform output lambda_function | xargs)\"\n",
    "        ```\n",
    "   \n",
    "   - *Step 6:* After applying the Terraform changes, this step builds a Docker image from the code in the ```06-best-practices/code``` directory of the VM and pushes it to Amazon Elastic Container Registry (ECR). The image URI is saved to the output variable ```image_uri``` by the GitHub Actions special syntax ```echo ...```. The ```image_uri``` output variable can be then accessed in subsequent steps.\n",
    "```yaml\n",
    "          - name: Login to Amazon ECR\n",
    "            id: login-ecr\n",
    "            uses: aws-actions/amazon-ecr-login@v1\n",
    "\n",
    "          - name: Build, tag, and push image to Amazon ECR\n",
    "            id: build-image-step\n",
    "            working-directory: \"06-best-practices/code\"\n",
    "            env:\n",
    "              ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}\n",
    "              ECR_REPOSITORY: ${{ steps.tf-apply.outputs.ecr_repo }}\n",
    "              IMAGE_TAG: \"latest\"   # ${{ github.sha }}\n",
    "            run: |\n",
    "              docker build -t ${ECR_REGISTRY}/${ECR_REPOSITORY}:${IMAGE_TAG} .\n",
    "              docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\n",
    "              echo \"::set-output name=image_uri::$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be6b363",
   "metadata": {},
   "source": [
    "   - *Step 7:* Retrieve model artifacts from a development S3 bucket and copy them to the production S3 bucket. The latest model version is identified and saved to the variable ```run_id```. The commands after ```run:``` reproduce the lines in ```deploy_manual.sh``` \n",
    "```yaml\n",
    "          - name: Get model artifacts\n",
    "          # The steps here are not suited for production.\n",
    "          # In practice, retrieving the latest model version or RUN_ID from a service\n",
    "          # like MLflow or DVC can also be integrated into a CI/CD pipeline.\n",
    "          # But due to the limited scope of this workshop, we would be keeping \n",
    "          # things simple.\n",
    "          # In practice, you would also have a separate training pipeline to write \n",
    "          # new model artifacts to your Model Bucket in Prod.\n",
    "\n",
    "            id: get-model-artifacts\n",
    "            working-directory: \"06-best-practices/code\"\n",
    "            env:\n",
    "              MODEL_BUCKET_DEV: \"mlflow-models-alexey\"\n",
    "              MODEL_BUCKET_PROD: ${{ steps.tf-apply.outputs.model_bucket }}\n",
    "            run: |\n",
    "              export RUN_ID=$(aws s3api list-objects-v2 --bucket ${MODEL_BUCKET_DEV} \\\n",
    "              --query 'sort_by(Contents, &LastModified)[-1].Key' --output=text | cut -f2 -d/)\n",
    "              aws s3 sync s3://${MODEL_BUCKET_DEV} s3://${MODEL_BUCKET_PROD}\n",
    "              echo \"::set-output name=run_id::${RUN_ID}\"\n",
    "```   \n",
    "\n",
    "   - *Step 8:* Update the AWS Lambda function with the new model artifacts and other environment variables. The Lambda function is updated using the AWS CLI. \n",
    "       - The ```aws lambda get-function``` command is used to check the status of the Lambda function update. \n",
    "       - Once the update status is no longer \"InProgress,\" the script proceeds to update the Lambda function's configuration using the ```aws lambda update-function-configuration``` command.\n",
    "       \n",
    "   Ideally, it's best to keep a sleep timer before the Lambda gets updated. In this case it's not really necessary, as we are creating the Terraform infra in the same workflow (sequentially). In a more realistic scenario they would be two different workflows and be executed in parallel, thus the sleep timer may be necessary to wait for the infra to be ready.\n",
    "```yaml\n",
    "          - name: Update Lambda\n",
    "            env:\n",
    "              LAMBDA_FUNCTION: ${{ steps.tf-apply.outputs.lambda_function }}\n",
    "              PREDICTIONS_STREAM_NAME: ${{ steps.tf-apply.outputs.predictions_stream_name }}\n",
    "              MODEL_BUCKET: ${{ steps.tf-apply.outputs.model_bucket }}\n",
    "              RUN_ID: ${{ steps.get-model-artifacts.outputs.run_id }}\n",
    "            run: |\n",
    "              variables=\"{ \\\n",
    "                        PREDICTIONS_STREAM_NAME=$PREDICTIONS_STREAM_NAME, MODEL_BUCKET=$MODEL_BUCKET, RUN_ID=$RUN_ID \\\n",
    "                        }\"\n",
    "\n",
    "              STATE=$(aws lambda get-function --function-name $LAMBDA_FUNCTION --region \"eu-west-1\" --query 'Configuration.LastUpdateStatus' --output text)\n",
    "                  while [[ \"$STATE\" == \"InProgress\" ]]\n",
    "                  do\n",
    "                      echo \"sleep 5sec ....\"\n",
    "                      sleep 5s\n",
    "                      STATE=$(aws lambda get-function --function-name $LAMBDA_FUNCTION --region \"eu-west-1\" --query 'Configuration.LastUpdateStatus' --output text)\n",
    "                      echo $STATE\n",
    "                  done\n",
    "\n",
    "              aws lambda update-function-configuration --function-name $LAMBDA_FUNCTION \\\n",
    "                        --environment \"Variables=${variables}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc3a49",
   "metadata": {},
   "source": [
    "### 3.2 Execute CD workflow\n",
    "\n",
    "1. Go to the root of your repository\n",
    "2. Make sure you are in the feature branch ```feature/week6b-iac```\n",
    "3. Commit changes ```$ git commit -m \"cd-deploy\"```\n",
    "4. Push to the feature branch, ```$ git push origin feature/week6b-iac```\n",
    "5. Perform CI workflow (steps 5 & 6 from section 2.2)\n",
    "6. Let's merge the pull-request to the ```develop``` branch\n",
    "\n",
    "![title](images/cd-workflow.png)\n",
    "\n",
    "7. This triggers our CD workflow now:\n",
    "\n",
    "![title](images/cd-workflow2.png)\n",
    "\n",
    "And in more detail:\n",
    "\n",
    "![title](images/cd-workflow2_detail.png)\n",
    "\n",
    "8. Now you have both the CI and CD workflows deployed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlops-zoomcamp]",
   "language": "python",
   "name": "conda-env-mlops-zoomcamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
